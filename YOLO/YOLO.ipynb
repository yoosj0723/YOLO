{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Sep 24 19:51:27 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 556.12                 Driver Version: 556.12         CUDA Version: 12.5     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3090      WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "|  0%   39C    P8             27W /  420W |     494MiB /  24576MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      1080    C+G   ...\\User\\mentalmentor\\mentalmentor.exe      N/A      |\n",
      "|    0   N/A  N/A      5216    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A      9824    C+G   ...les\\Microsoft OneDrive\\OneDrive.exe      N/A      |\n",
      "|    0   N/A  N/A     11340    C+G   ...yb3d8bbwe\\Microsoft.Msn.Weather.exe      N/A      |\n",
      "|    0   N/A  N/A     11780    C+G   ...573_x64__8wekyb3d8bbwe\\ms-teams.exe      N/A      |\n",
      "|    0   N/A  N/A     12016    C+G   ...on\\128.0.2739.79\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A     13084    C+G   ...2txyewy\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     13496    C+G   ...oogle\\Chrome\\Application\\chrome.exe      N/A      |\n",
      "|    0   N/A  N/A     15644    C+G   ....Search_cw5n1h2txyewy\\SearchApp.exe      N/A      |\n",
      "|    0   N/A  N/A     16824    C+G   ...siveControlPanel\\SystemSettings.exe      N/A      |\n",
      "|    0   N/A  N/A     17312    C+G   C:\\Windows\\explorer.exe                     N/A      |\n",
      "|    0   N/A  N/A     18400    C+G   ...Programs\\Microsoft VS Code\\Code.exe      N/A      |\n",
      "|    0   N/A  N/A     18632    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A     18884    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     20272    C+G   ...ram Files (x86)\\AnyDesk\\AnyDesk.exe      N/A      |\n",
      "|    0   N/A  N/A     20616    C+G   ...crosoft\\Edge\\Application\\msedge.exe      N/A      |\n",
      "|    0   N/A  N/A     21200    C+G   ...b3d8bbwe\\Microsoft.Media.Player.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in c:\\users\\user\\anaconda3\\envs\\e-gov\\lib\\site-packages (8.2.79)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.0 in c:\\users\\user\\anaconda3\\envs\\e-gov\\lib\\site-packages (from ultralytics) (1.23.5)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\user\\anaconda3\\envs\\e-gov\\lib\\site-packages (from ultralytics) (3.9.0)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\user\\anaconda3\\envs\\e-gov\\lib\\site-packages (from ultralytics) (4.10.0.84)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\user\\anaconda3\\envs\\e-gov\\lib\\site-packages (from ultralytics) (10.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\user\\anaconda3\\envs\\e-gov\\lib\\site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\user\\anaconda3\\envs\\e-gov\\lib\\site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\user\\anaconda3\\envs\\e-gov\\lib\\site-packages (from ultralytics) (1.13.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\user\\anaconda3\\envs\\e-gov\\lib\\site-packages (from ultralytics) (1.12.0+cu113)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\user\\anaconda3\\envs\\e-gov\\lib\\site-packages (from ultralytics) (0.13.0+cu113)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\user\\anaconda3\\envs\\e-gov\\lib\\site-packages (from ultralytics) (4.66.4)\n",
      "Requirement already satisfied: psutil in c:\\users\\user\\anaconda3\\envs\\e-gov\\lib\\site-packages (from ultralytics) (5.9.0)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\user\\anaconda3\\envs\\e-gov\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\user\\anaconda3\\envs\\e-gov\\lib\\site-packages (from ultralytics) (2.2.2)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\user\\anaconda3\\envs\\e-gov\\lib\\site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in c:\\users\\user\\anaconda3\\envs\\e-gov\\lib\\site-packages (from ultralytics) (2.0.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\anaconda3\\envs\\e-gov\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\anaconda3\\envs\\e-gov\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\anaconda3\\envs\\e-gov\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\user\\anaconda3\\envs\\e-gov\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\envs\\e-gov\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\user\\anaconda3\\envs\\e-gov\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\anaconda3\\envs\\e-gov\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\user\\anaconda3\\envs\\e-gov\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (6.4.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\anaconda3\\envs\\e-gov\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\anaconda3\\envs\\e-gov\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\envs\\e-gov\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\envs\\e-gov\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\envs\\e-gov\\lib\\site-packages (from requests>=2.23.0->ultralytics) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\envs\\e-gov\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2024.6.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\user\\anaconda3\\envs\\e-gov\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\envs\\e-gov\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\user\\anaconda3\\envs\\e-gov\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib>=3.3.0->ultralytics) (3.19.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\anaconda3\\envs\\e-gov\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\anaconda3\\envs\\e-gov\\lib\\site-packages (1.5.0)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\user\\anaconda3\\envs\\e-gov\\lib\\site-packages (from scikit-learn) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\user\\anaconda3\\envs\\e-gov\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\user\\anaconda3\\envs\\e-gov\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\user\\anaconda3\\envs\\e-gov\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 경로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 특정 경로 설정 (OneDrive의 바탕 화면 경로)\n",
    "desktop_path = r\"C:/Users/User/Desktop/YOLO_0924\"\n",
    "\n",
    "# 데이터셋 경로 설정\n",
    "image_dir = os.path.join(desktop_path, 'yolodataset/images')\n",
    "label_dir = os.path.join(desktop_path, 'yolodataset/labels')\n",
    "\n",
    "train_image_dir = os.path.join(desktop_path, 'dataset/train/images')\n",
    "train_label_dir = os.path.join(desktop_path, 'dataset/train/labels')\n",
    "val_image_dir = os.path.join(desktop_path, 'dataset/val/images')\n",
    "val_label_dir = os.path.join(desktop_path, 'dataset/val/labels')\n",
    "test_image_dir = os.path.join(desktop_path, 'dataset/test/images')\n",
    "test_label_dir = os.path.join(desktop_path, 'dataset/test/labels')\n",
    "\n",
    "# 필요한 디렉토리 생성\n",
    "os.makedirs(train_image_dir, exist_ok=True)\n",
    "os.makedirs(train_label_dir, exist_ok=True)\n",
    "os.makedirs(val_image_dir, exist_ok=True)\n",
    "os.makedirs(val_label_dir, exist_ok=True)\n",
    "os.makedirs(test_image_dir, exist_ok=True)\n",
    "os.makedirs(test_label_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split train, test, val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 파일 리스트와 라벨 파일 리스트 얻기\n",
    "image_files = sorted(os.listdir(image_dir))\n",
    "label_files = sorted(os.listdir(label_dir))\n",
    "\n",
    "# 이미지 파일 이름과 라벨 파일 이름에서 확장자 제거\n",
    "image_files_set = set([os.path.splitext(f)[0] for f in image_files])\n",
    "label_files_set = set([os.path.splitext(f)[0] for f in label_files])\n",
    "\n",
    "# 공통된 파일 리스트 생성\n",
    "common_files = list(image_files_set & label_files_set)\n",
    "\n",
    "# 이미지 파일과 라벨 파일의 전체 파일 경로를 생성\n",
    "image_files = [f + os.path.splitext(image_files[0])[1] for f in common_files]\n",
    "label_files = [f + os.path.splitext(label_files[0])[1] for f in common_files]\n",
    "\n",
    "# 이미지가 없는 라벨 파일 처리\n",
    "if label_files:\n",
    "    label_ext = os.path.splitext(label_files[0])[1]\n",
    "else:\n",
    "    print(\"라벨 파일이 없습니다.\")\n",
    "    label_ext = \"\"\n",
    "\n",
    "if label_ext:\n",
    "    no_image_labels = [f + label_ext for f in (label_files_set - image_files_set)]\n",
    "else:\n",
    "    no_image_labels = []\n",
    "\n",
    "# 데이터셋을 학습, 검증, 테스트로 나누기 (예: 70% 학습, 20% 검증, 10% 테스트)\n",
    "train_images, temp_images, train_labels, temp_labels = train_test_split(\n",
    "    image_files, label_files, test_size=0.3, random_state=42\n",
    ")\n",
    "val_images, test_images, val_labels, test_labels = train_test_split(\n",
    "    temp_images, temp_labels, test_size=0.33, random_state=42\n",
    ") # 0.33 * 0.3 = 0.1\n",
    "\n",
    "# 이미지가 없는 라벨 파일 처리 (비어있는 경우 처리 건너뜀)\n",
    "if no_image_labels:\n",
    "    train_labels_no_image, temp_labels_no_image = train_test_split(\n",
    "        no_image_labels, test_size=0.3, random_state=42\n",
    "    )\n",
    "    val_labels_no_image, test_labels_no_image = train_test_split(\n",
    "        temp_labels_no_image, test_size=0.33, random_state=42\n",
    "    ) # 0.33 * 0.3 = 0.1\n",
    "else:\n",
    "    train_labels_no_image, val_labels_no_image, test_labels_no_image = [], [], []\n",
    "\n",
    "# 파일 이동 함수\n",
    "def move_files(file_list, src_dir, dst_dir):\n",
    "    for file_name in file_list:\n",
    "        src_path = os.path.join(src_dir, file_name)\n",
    "        dst_path = os.path.join(dst_dir, file_name)\n",
    "        if os.path.exists(src_path):\n",
    "            shutil.move(src_path, dst_path)\n",
    "        else:\n",
    "            print(f\"파일이 존재하지 않습니다: {src_path}\")\n",
    "\n",
    "# 학습 데이터 이동\n",
    "move_files(train_images, image_dir, train_image_dir)\n",
    "move_files(train_labels, label_dir, train_label_dir)\n",
    "move_files(train_labels_no_image, label_dir, train_label_dir)\n",
    "\n",
    "# 검증 데이터 이동\n",
    "move_files(val_images, image_dir, val_image_dir)\n",
    "move_files(val_labels, label_dir, val_label_dir)\n",
    "move_files(val_labels_no_image, label_dir, val_label_dir)\n",
    "\n",
    "# 테스트 데이터 이동\n",
    "move_files(test_images, image_dir, test_image_dir)\n",
    "move_files(test_labels, label_dir, test_label_dir)\n",
    "move_files(test_labels_no_image, label_dir, test_label_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.2.100 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.2.63  Python-3.12.4 torch-2.3.1 CUDA:0 (NVIDIA GeForce RTX 3090, 24576MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8l.yaml, data=C:/Users/User/Desktop/YOLO_0924/datasetV3.yaml, epochs=300, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train2\n",
      "Overriding model.yaml nc=80 with nc=72\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
      "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
      "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n",
      " 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n",
      " 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n",
      " 22        [15, 18, 21]  1   5638312  ultralytics.nn.modules.head.Detect           [72, [256, 512, 512]]         \n",
      "YOLOv8l summary: 365 layers, 43,685,352 parameters, 43,685,336 gradients, 165.7 GFLOPs\n",
      "\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6.25M/6.25M [00:00<00:00, 11.9MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\User\\Desktop\\YOLO_0924\\dataset\\train\\labels... 7414 images, 0 backgrounds, 0 corrupt: 100%|██████████| 7414/7414 [00:03<00:00, 1975.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\User\\Desktop\\YOLO_0924\\dataset\\train\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\User\\Desktop\\YOLO_0924\\dataset\\val\\labels... 2129 images, 0 backgrounds, 0 corrupt: 100%|██████████| 2129/2129 [00:01<00:00, 1212.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\User\\Desktop\\YOLO_0924\\dataset\\val\\labels.cache\n",
      "Plotting labels to runs\\detect\\train2\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train2\u001b[0m\n",
      "Starting training for 300 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/464 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import os \n",
    "\n",
    "# YOLOv8n 모델 로드\n",
    "\n",
    "model = YOLO('yolov8l.yaml')\n",
    "\n",
    "# yaml 파일 로드\n",
    "yaml_file = \"C:/Users/User/Desktop/YOLO_0924/datasetV3.yaml\"\n",
    "\n",
    "\n",
    "# 모델 학습\n",
    "model.train(data=yaml_file, epochs=300)\n",
    "\n",
    "# 학습된 모델 평가\n",
    "results = model.val()\n",
    "\n",
    "# 모델 저장 경로 설정\n",
    "model_save_dir = 'C:/Users/User/Desktop/YOLO_0924/model'\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "model_save_path = os.path.join(model_save_dir, 'best.pt')\n",
    "\n",
    "# 모델 저장 \n",
    "if hasattr(model, 'ckpt') and model.ckpt is not None:\n",
    "    model.save(model_save_path)\n",
    "    print(f\"모델이 성공적으로 저장되었습니다: {model_save_path}\")\n",
    "else:\n",
    "    print(\"체크포인트가 없습니다. 모델이 제대로 학습되었는지 확인하세요.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn  # Seaborn 라이브러리 추가\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "\n",
    "#classes\n",
    "classes = [\n",
    "    \n",
    "]\n",
    "\n",
    "# Confusion Matrix 저장 및 해상도 조정\n",
    "def plot_confusion_matrix(matrix, save_path, class_names):\n",
    "    # 값이 0인 곳은 NaN으로 바꿔서 빈칸으로 표시\n",
    "    array = np.where(matrix == 0, np.nan, matrix)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(20, 20))  # 그림 크기를 20x20으로 설정\n",
    "    sn.heatmap(array, annot=True, cmap='Blues', fmt='.0f', square=True, vmin=0.0, xticklabels=class_names, yticklabels=class_names, annot_kws={\"size\": 8}).set_facecolor((1, 1, 1))\n",
    "    \n",
    "    ax.set_xlabel('True Labels')\n",
    "    ax.set_ylabel('Predicted Labels')\n",
    "    ax.set_title('Confusion Matrix')\n",
    "    \n",
    "    # 고해상도로 저장 (dpi=400)\n",
    "    plt.savefig(save_path, dpi=400)\n",
    "    plt.close()\n",
    "\n",
    "# Confusion matrix 데이터 가져오기\n",
    "conf_matrix = results.confusion_matrix.matrix  # matrix 속성으로 접근하여 confusion matrix를 numpy 배열로 변환\n",
    "\n",
    "# confusion matrix를 저장할 경로 설정\n",
    "conf_matrix_save_path = os.path.join(model_save_dir, 'confusion_matrix_high_res.png')\n",
    "\n",
    "# confusion matrix 플로팅 및 저장\n",
    "plot_confusion_matrix(conf_matrix, conf_matrix_save_path, classes)\n",
    "print(f\"Confusion matrix가 저장되었습니다: {conf_matrix_save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## filltered_ConfusionMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 클래스 목록\n",
    "classes = [\n",
    "    \n",
    "]\n",
    "\n",
    "# 포함할 클래스 목록\n",
    "include_classes = [\n",
    "    \n",
    "]\n",
    "\n",
    "# 제외할 클래스 목록 생성\n",
    "exclude_classes = [cls for cls in classes if cls not in include_classes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix 저장 및 해상도 조정\n",
    "def plot_confusion_matrix(matrix, save_path, class_names, dpi):\n",
    "    # 값이 0인 곳은 NaN으로 바꿔서 빈칸으로 표시\n",
    "    array = np.where(matrix == 0, np.nan, matrix)\n",
    "    \n",
    "    # 그림 크기를 조정하여 클래스 이름이 잘 보이도록 설정\n",
    "    fig, ax = plt.subplots(figsize=(20, 20))  # 그림 크기를 20x20으로 설정하여 텍스트 간격 확보\n",
    "    sn.heatmap(array, annot=True, cmap='coolwarm', fmt='.0f', square=True, vmin=0.0, xticklabels=class_names, yticklabels=class_names, annot_kws={\"size\": 8}).set_facecolor((1, 1, 1))\n",
    "    \n",
    "    ax.set_xlabel('True Labels', fontsize=12)\n",
    "    ax.set_ylabel('Predicted Labels', fontsize=12)\n",
    "    ax.set_title('Confusion Matrix', fontsize=15)\n",
    "    \n",
    "    # x축과 y축의 텍스트 크기 조정\n",
    "    ax.xaxis.set_tick_params(labelsize=10)\n",
    "    ax.yaxis.set_tick_params(labelsize=10)\n",
    "    \n",
    "    # 해상도 조정\n",
    "    plt.tight_layout()  # 여백을 자동으로 조정\n",
    "    plt.savefig(save_path, dpi=dpi)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "#Confusion Matrix를 fillterd Confusion Matrix로 변환\n",
    "def convert_Matrix():\n",
    "    # Confusion matrix 데이터 가져오기\n",
    "    conf_matrix = results.confusion_matrix.matrix  # matrix 속성으로 접근하여 confusion matrix를 numpy 배열로 변환\n",
    "    \n",
    "    # 제외할 클래스의 인덱스 추출\n",
    "    exclude_indices = [classes.index(cls) for cls in exclude_classes]\n",
    "    \n",
    "    # 해당 인덱스를 사용하여 행과 열 제거\n",
    "    filtered_conf_matrix = np.delete(conf_matrix, exclude_indices, axis=0)  # 행 제거\n",
    "    filtered_conf_matrix = np.delete(filtered_conf_matrix, exclude_indices, axis=1)  # 열 제거\n",
    "        \n",
    "    # exclude_classes에 해당하는 클래스 목록만 남김\n",
    "    filtered_classes = [cls for i, cls in enumerate(classes) if i not in exclude_indices]\n",
    "\n",
    "    return filtered_conf_matrix, filtered_classes\n",
    "\n",
    "\n",
    "def main():\n",
    "    # confusion matrix를 저장할 경로 설정\n",
    "    conf_matrix_save_path = os.path.join(model_save_dir, 'confusion_matrix_filtered.png')\n",
    "    \n",
    "    # 필터링된 confusion matrix 플로팅 및 저장 ***dpi(해상도) 설정\n",
    "    plot_confusion_matrix(filtered_conf_matrix, conf_matrix_save_path, filtered_conf_matrix, dpi=1600)\n",
    "    print(f\"Filtered confusion matrix가 저장되었습니다: {conf_matrix_save_path}\")\n",
    "\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_YOLO",
   "language": "python",
   "name": "venv_yolo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
